---
title: 5.5 新范式：大模型(SAM)与生成式AI
description: 从“分割即服务”到生成式先验：医学影像中的 Foundation Model 时代
---

# 5.5 新范式：大模型(SAM)与生成式AI

过去十年，医学影像 AI 的主线是：用 U-Net/3D-CNN/Transformer 在单任务上“训练一个模型”。而近两年出现了更像“平台能力”的新范式：**基础模型（Foundation Model）** 与 **生成式模型（Generative AI）**。

它们带来的变化不是“再涨 1 个百分点”，而是：数据标注方式、交互方式、甚至工具链都可能被重写。

---

## 🧠 1. SAM：从“分割模型”到“交互式分割引擎”

### 1.1 SAM 解决了什么问题？

传统分割的主要瓶颈往往不是网络结构，而是：

- 标注昂贵（像素级标注成本很高）
- 跨中心泛化弱（扫描参数/设备差异）
- 任务碎片化（一个器官一个模型）

SAM（Segment Anything Model）提出一种思路：把分割变成“**提示驱动（promptable）**”的交互系统。

### 1.2 SAM 在医学影像里的常见使用方式

- **交互式标注**：医生/标注员点几下（点/框/涂鸦），快速得到 mask
- **半自动标注流水线**：SAM 产出候选，人工修正 → 显著加速数据构建
- **作为下游模型的数据引擎**：先用 SAM 生成粗标注，再训练专用 nnU-Net 做高精度

:::: warning ⚠️ SAM 不是“直接拿来就能分割所有医学器官”
SAM 的预训练主要来自自然图像，医学影像的灰度分布、噪声形态与结构特征差异很大。常见问题包括：
- 对低对比边界不稳
- 对体数据（3D）需要额外设计（逐切片 vs 3D SAM）
- 对小病灶（tiny lesion）容易漏检
::::

---

## 🧬 2. 生成式 AI：用“先验”补全缺失信息

生成式模型（GAN / Diffusion / Flow / Autoregressive）在医学影像常见落点：

### 2.1 去噪、去伪影与超分辨

- 低剂量 CT 去噪
- MRI 加速重建（欠采样 → 复原）
- 伪影抑制（金属伪影、运动伪影）
- 超分辨率（尤其是薄层重建/重采样场景）

### 2.2 合成数据与数据增强

- 合成 “罕见病灶” 提升长尾覆盖
- 跨域风格迁移（不同中心/设备）做 domain augmentation

### 2.3 多模态补全（modality completion）

例如：由 MR 估计 pseudo-CT，用于放疗计划/衰减校正等（需非常谨慎评估误差）。

:::: warning ⚠️ 生成式模型的核心风险：幻觉（hallucination）
医学影像里“生成得像”远远不够——最怕的是：
- 生成不存在的结构/病灶（假阳性）
- 把真实病灶抹掉（假阴性）

因此临床相关任务必须配合：不确定性估计、质量控制、可追溯性与严格验证。
::::

---

## 🧩 3. 实践建议：怎么把新范式用“对”？

### 3.1 一个稳妥的落地路径

1. **先做标注提效**：用 SAM 作为交互标注工具（低风险、高收益）
2. **再做下游专用模型**：用 nnU-Net/专用 3D 网络做最终推理
3. **生成式能力放在“辅助环节”**：例如去噪/伪影抑制，但要有明确 QC

### 3.2 建议你关注的评估维度

- **任务指标**：Dice/IoU、敏感性、特异性、AUROC 等
- **安全指标**：假阴性成本、误差上界、失败模式
- **数据外推**：跨中心/跨设备/跨人群泛化

---

## 💡 小结

1. **SAM 的价值**更多体现在“交互式标注与数据引擎”，而不是“一步到位替代专用模型”。
2. **生成式 AI** 能提供强先验与强表达，但必须正视“幻觉风险”，并建立可控的验证与质量控制体系。


